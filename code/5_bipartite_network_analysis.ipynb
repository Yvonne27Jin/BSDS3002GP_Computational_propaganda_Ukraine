{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-3f3f8eb7392e>:2: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,14,15,16,17,18,19,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(\"nodelist2_poli.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>username</th>\n",
       "      <th>textid</th>\n",
       "      <th>location</th>\n",
       "      <th>language</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tweetcreatedts</th>\n",
       "      <th>retweetcount</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>tags_splitted</th>\n",
       "      <th>tags_lower</th>\n",
       "      <th>pro_Russian</th>\n",
       "      <th>pro_Ukraine</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>NodeType</th>\n",
       "      <th>nodeInG1</th>\n",
       "      <th>nodeInG2</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4832941924</td>\n",
       "      <td>Mari_Berbec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>en</td>\n",
       "      <td>1497476520742309891</td>\n",
       "      <td>2022-02-26 07:39:58</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'text': 'putin', 'indices': [53, 59]}, {'tex...</td>\n",
       "      <td>@charlieweissr Socialism has nothing to do wit...</td>\n",
       "      <td>...</td>\n",
       "      <td>2848.0</td>\n",
       "      <td>['putin', 'trump']</td>\n",
       "      <td>['putin', 'trump']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.832942e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412597196</td>\n",
       "      <td>plaroch</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "      <td>1496862205584855054</td>\n",
       "      <td>2022-02-24 14:58:54</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'text': 'Ukraine', 'indices': [32, 40]}, {'t...</td>\n",
       "      <td>Ce fut une terrible erreur de l'#Ukraine de se...</td>\n",
       "      <td>...</td>\n",
       "      <td>141300.0</td>\n",
       "      <td>['Ukraine', 'Poutine']</td>\n",
       "      <td>['ukraine', 'poutine']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.125972e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1494370657152675840</td>\n",
       "      <td>touchsoundart</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Macau</td>\n",
       "      <td>en</td>\n",
       "      <td>1497725055920345088</td>\n",
       "      <td>2022-02-27 00:07:34</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'text': 'nft', 'indices': [76, 80]}, {'text'...</td>\n",
       "      <td>Hello friends, I invite you for a walk around ...</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>['nft', '35mm', 'NFTCommunity', 'Ukraine']</td>\n",
       "      <td>['nft', '35mm', 'nftcommunity', 'ukraine']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.494371e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2573523092</td>\n",
       "      <td>deliciousndprvd</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1496849491424694279</td>\n",
       "      <td>2022-02-24 14:08:23</td>\n",
       "      <td>2208</td>\n",
       "      <td>[{'text': 'Ukraine', 'indices': [37, 45]}, {'t...</td>\n",
       "      <td>To all of those in #Ukraine who are looking fo...</td>\n",
       "      <td>...</td>\n",
       "      <td>38050.0</td>\n",
       "      <td>['Ukraine', 'Poland']</td>\n",
       "      <td>['ukraine', 'poland']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.573523e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1489178054513545216</td>\n",
       "      <td>poposogolo</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it</td>\n",
       "      <td>1497219893866999809</td>\n",
       "      <td>2022-02-25 14:40:14</td>\n",
       "      <td>15</td>\n",
       "      <td>[{'text': 'Difesa', 'indices': [70, 77]}]</td>\n",
       "      <td>Con l’incarico di Segretario del Consiglio Sup...</td>\n",
       "      <td>...</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>['Difesa']</td>\n",
       "      <td>['difesa']</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.489178e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                userid         username  textid         location language  \\\n",
       "0           4832941924      Mari_Berbec     1.0  Berlin, Germany       en   \n",
       "1            412597196          plaroch     7.0              NaN       fr   \n",
       "2  1494370657152675840    touchsoundart    11.0            Macau       en   \n",
       "3           2573523092  deliciousndprvd    17.0              NaN       en   \n",
       "4  1489178054513545216       poposogolo    22.0              NaN       it   \n",
       "\n",
       "               tweetid       tweetcreatedts retweetcount  \\\n",
       "0  1497476520742309891  2022-02-26 07:39:58            0   \n",
       "1  1496862205584855054  2022-02-24 14:58:54            0   \n",
       "2  1497725055920345088  2022-02-27 00:07:34            1   \n",
       "3  1496849491424694279  2022-02-24 14:08:23         2208   \n",
       "4  1497219893866999809  2022-02-25 14:40:14           15   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [{'text': 'putin', 'indices': [53, 59]}, {'tex...   \n",
       "1  [{'text': 'Ukraine', 'indices': [32, 40]}, {'t...   \n",
       "2  [{'text': 'nft', 'indices': [76, 80]}, {'text'...   \n",
       "3  [{'text': 'Ukraine', 'indices': [37, 45]}, {'t...   \n",
       "4          [{'text': 'Difesa', 'indices': [70, 77]}]   \n",
       "\n",
       "                                                text  ... totaltweets  \\\n",
       "0  @charlieweissr Socialism has nothing to do wit...  ...      2848.0   \n",
       "1  Ce fut une terrible erreur de l'#Ukraine de se...  ...    141300.0   \n",
       "2  Hello friends, I invite you for a walk around ...  ...        53.0   \n",
       "3  To all of those in #Ukraine who are looking fo...  ...     38050.0   \n",
       "4  Con l’incarico di Segretario del Consiglio Sup...  ...      2261.0   \n",
       "\n",
       "                                tags_splitted  \\\n",
       "0                          ['putin', 'trump']   \n",
       "1                      ['Ukraine', 'Poutine']   \n",
       "2  ['nft', '35mm', 'NFTCommunity', 'Ukraine']   \n",
       "3                       ['Ukraine', 'Poland']   \n",
       "4                                  ['Difesa']   \n",
       "\n",
       "                                   tags_lower  pro_Russian pro_Ukraine  \\\n",
       "0                          ['putin', 'trump']        False       False   \n",
       "1                      ['ukraine', 'poutine']        False       False   \n",
       "2  ['nft', '35mm', 'nftcommunity', 'ukraine']        False       False   \n",
       "3                       ['ukraine', 'poland']        False       False   \n",
       "4                                  ['difesa']        False       False   \n",
       "\n",
       "  Neutral NodeType nodeInG1 nodeInG2            ID  \n",
       "0    True  Neutral     True     True  4.832942e+09  \n",
       "1    True  Neutral     True     True  4.125972e+08  \n",
       "2    True  Neutral     True     True  1.494371e+18  \n",
       "3    True  Neutral     True     True  2.573523e+09  \n",
       "4   False  Unknown     True     True  1.489178e+18  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get nodes for bipartite network\n",
    "users = pd.read_csv(\"nodelist2_poli.csv\")\n",
    "# tweets = pd.read_csv(\"tweet_nodes.csv\")\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0               userid         username   location  \\\n",
      "0       58294  1273101694268837890     nowhere_safe    Web3.0    \n",
      "1       58303   724605084169060353  VillTjanaPengar        NaN   \n",
      "2       58311             19535996       stemdesign     London   \n",
      "3       58339   861486301211709440  quentinhubert99   Tergnier   \n",
      "4       58340             51813322          EduA001  Venezuela   \n",
      "\n",
      "                usercreatedts  following  followers  totaltweets  \n",
      "0  2020-06-17 03:54:42.000000       2421        798         1693  \n",
      "1  2016-04-25 14:24:49.000000        119          1            1  \n",
      "2  2009-01-26 14:22:06.000000        591        363         4284  \n",
      "3  2017-05-08 07:41:54.000000        131        136         6102  \n",
      "4  2009-06-28 19:20:19.000000       1371       2949       102887  \n",
      "   Unnamed: 0  textid                                               text  \\\n",
      "0       58294   58294  I learn to use #Kalashnikov and prepare to bea...   \n",
      "1       58303   58303  .@ZelenskyyUa's tv address to the Russian (!) ...   \n",
      "2       58339   58339  The Anonymous collective is officially in cybe...   \n",
      "3       58433   58433  So I've been asked what my advice would be to ...   \n",
      "4       58488   58488  Spoke with #Poland's President @AndrzejDuda on...   \n",
      "\n",
      "                                            hashtags  \n",
      "0     [{'text': 'Kalashnikov', 'indices': [35, 47]}]  \n",
      "1                                                 []  \n",
      "2  [{'text': 'Anonymous', 'indices': [101, 111]},...  \n",
      "3                                                 []  \n",
      "4  [{'text': 'Poland', 'indices': [32, 39]}, {'te...  \n"
     ]
    }
   ],
   "source": [
    "print(users.head())\n",
    "print(tweets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the first column (old indices)\n",
    "users = users.drop(['Unnamed: 0'], axis=1)\n",
    "tweets = tweets.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get edge list for bipartite network\n",
    "edges = pd.read_csv(\"edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16315, 7)\n",
      "(5333, 3)\n",
      "(17255, 2)\n"
     ]
    }
   ],
   "source": [
    "print(users.shape)\n",
    "print(tweets.shape)\n",
    "print(edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User attributes: ['userid' 'username' 'location' 'usercreatedts' 'following' 'followers'\n",
      " 'totaltweets']\n",
      "Tweet attributes: ['textid' 'text' 'hashtags']\n"
     ]
    }
   ],
   "source": [
    "print(\"User attributes:\",users.columns.values)\n",
    "print(\"Tweet attributes:\",tweets.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph with nodes' attributes\n",
    "B = nx.Graph()\n",
    "B.add_nodes_from(users[\"userid\"], bipartite=0, username=users[\"userid\"],location=users[\"location\"],\n",
    "                 usercreatedts=users[\"usercreatedts\"], following=users[\"following\"],followers=users[\"followers\"])\n",
    "B.add_nodes_from(tweets[\"textid\"], bipartite=1, text=tweets[\"text\"], hashtags=tweets[\"hashtags\"])\n",
    "B.add_edges_from(edges.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 16315 nodes and 256226 edges\n",
      "Graph with 5244 nodes and 1114 edges\n"
     ]
    }
   ],
   "source": [
    "from networkx.algorithms import bipartite\n",
    "\n",
    "# Create one-mode networks\n",
    "users_nodes = {n for n, a in B.nodes(data=True) if a[\"bipartite\"] == 0}\n",
    "tweets_nodes = set(B) - users_nodes\n",
    "\n",
    "B_users = bipartite.projected_graph(B, users_nodes)\n",
    "B_tweets = bipartite.projected_graph(B, tweets_nodes)\n",
    "\n",
    "print(nx.info(B_users))\n",
    "print(nx.info(B_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_degcentrality = nx.degree_centrality(B_users)\n",
    "tweets_degcentrality = nx.degree_centrality(B_tweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected Network of Insects\n",
      "The network has 16315 nodes and 256226 edges.\n",
      "The network is weighted:\t\t False\n",
      "The network is directed:\t\t False\n",
      "The network is bipartite:\t\t False\n",
      "The network is connected:\t\t False\n",
      "The isolated node in the network:\t 2474\n",
      "-------------\n",
      "After deleting the isolated nodes, the network has 13841 nodes and 256226 edges.\n",
      "There are 1920 connected components in the network and the largest one has 2585 nodes.\n"
     ]
    }
   ],
   "source": [
    "# provide the summary information of two projected networks\n",
    "print('Projected Network of Insects')\n",
    "print(f'The network has {len(B_users.nodes)} nodes and {len(B_users.edges)} edges.')\n",
    "\n",
    "print(f'The network is weighted:\\t\\t {nx.is_weighted(B_users)}')\n",
    "print(f'The network is directed:\\t\\t {nx.is_directed(B_users)}')\n",
    "print(f'The network is bipartite:\\t\\t {nx.is_bipartite(B_users)}')\n",
    "print(f'The network is connected:\\t\\t {nx.is_connected(B_users)}')\n",
    "\n",
    "print(f'The isolated node in the network:\\t {len(list(nx.isolates(B_users)))}')\n",
    "B_users_del = B_users.copy()\n",
    "B_users_del.remove_nodes_from(list(nx.isolates(B_users_del))) # delete the isolated nodes\n",
    "\n",
    "print('-------------')\n",
    "print(f'After deleting the isolated nodes, the network has {len(B_users_del.nodes)} nodes and {len(B_users_del.edges)} edges.')\n",
    "# create a subgraph that is the largest connected component\n",
    "S_users_del = max(nx.connected_components(B_users_del), key=len)\n",
    "S_users_del = B_users_del.subgraph(S_users_del)\n",
    "\n",
    "B_users_del_comp = [len(c) for c in sorted(nx.connected_components(B_users_del), key=len, reverse=True)]\n",
    "print(f'There are {len(B_users_del_comp)} connected components in the network and the largest one has {max(B_users_del_comp)} nodes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Density:\t\t\t 0.041265397536394174\n",
      "Network diameter:\t\t 26\n",
      "Average shortest path length:\t 8.621868543813738\n",
      "Average degree:\t\t\t 106.62978723404255\n",
      "-------------\n",
      "Node with the highest degree centrality:\t\t 417128105\n",
      "Node with the lowest degree centrality:\t\t\t 1405773541866233866\n",
      "\n",
      "Node with the highest betweenese degree centrality:\t 389950297\n",
      "Node with the lowest betweenese degree centrality:\t 942452818312683520\n",
      "\n",
      "Node with the highest closeness degree centrality:\t 3055684983\n",
      "Node with the lowest closeness degree centrality:\t 831140867369005056\n",
      "\n",
      "Node with the highest eigenvector degree centrality:\t 417128105\n",
      "Node with the lowest eigenvector degree centrality:\t 44092408\n",
      "\n",
      "Node with the highest load degree centrality:\t\t 389950297\n",
      "Node with the lowest load degree centrality:\t\t 942452818312683520\n"
     ]
    }
   ],
   "source": [
    "print('-------------')\n",
    "print(f'Density:\\t\\t\\t {nx.density(S_users_del)}')\n",
    "print(f'Network diameter:\\t\\t {nx.diameter(S_users_del)}')\n",
    "print(f'Average shortest path length:\\t {nx.average_shortest_path_length(S_users_del)}')\n",
    "print(f'Average degree:\\t\\t\\t {sum([v for (u,v) in list(nx.degree(S_users_del))]) / len(S_users_del)}')\n",
    "print('-------------')\n",
    "degree_insect = dict(nx.degree_centrality(S_users_del))\n",
    "print(f'Node with the highest degree centrality:\\t\\t {max(degree_insect, key=degree_insect.get)}')\n",
    "print(f'Node with the lowest degree centrality:\\t\\t\\t {min(degree_insect, key=degree_insect.get)}')\n",
    "print('')\n",
    "betweenness = dict(nx.betweenness_centrality(S_users_del))\n",
    "print(f'Node with the highest betweenese degree centrality:\\t {max(betweenness, key=betweenness.get)}')\n",
    "print(f'Node with the lowest betweenese degree centrality:\\t {min(betweenness, key=betweenness.get)}')\n",
    "print('')\n",
    "closeness = dict(nx.closeness_centrality(S_users_del))\n",
    "print(f'Node with the highest closeness degree centrality:\\t {max(closeness, key=closeness.get)}')\n",
    "print(f'Node with the lowest closeness degree centrality:\\t {min(closeness, key=closeness.get)}')\n",
    "print('')\n",
    "eigenvector = dict(nx.eigenvector_centrality(S_users_del))\n",
    "print(f'Node with the highest eigenvector degree centrality:\\t {max(eigenvector, key=eigenvector.get)}')\n",
    "print(f'Node with the lowest eigenvector degree centrality:\\t {min(eigenvector, key=eigenvector.get)}')\n",
    "print('')\n",
    "load = dict(nx.load_centrality(S_users_del))\n",
    "print(f'Node with the highest load degree centrality:\\t\\t {max(load, key=load.get)}')\n",
    "print(f'Node with the lowest load degree centrality:\\t\\t {min(load, key=load.get)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected Network of Tweets\n",
      "The network has 5244 nodes and 1114 edges.\n",
      "The network is weighted:\t\t False\n",
      "The network is directed:\t\t False\n",
      "The network is bipartite:\t\t False\n",
      "The network is connected:\t\t False\n",
      "The number of isolated nodes in the network:\t 4105\n",
      "-------------\n",
      "After deleting the isolated nodes, the network has 1139 nodes and 1114 edges.\n",
      "There are 289 connected components in the network and the largest one has 288 nodes.\n"
     ]
    }
   ],
   "source": [
    "# provide the summary information of two projected networks\n",
    "print('Projected Network of Tweets')\n",
    "print(f'The network has {len(B_tweets.nodes)} nodes and {len(B_tweets.edges)} edges.')\n",
    "\n",
    "print(f'The network is weighted:\\t\\t {nx.is_weighted(B_tweets)}')\n",
    "print(f'The network is directed:\\t\\t {nx.is_directed(B_tweets)}')\n",
    "print(f'The network is bipartite:\\t\\t {nx.is_bipartite(B_tweets)}')\n",
    "print(f'The network is connected:\\t\\t {nx.is_connected(B_tweets)}')\n",
    "\n",
    "print(f'The number of isolated nodes in the network:\\t {len(list(nx.isolates(B_tweets)))}')\n",
    "B_tweets_del = B_tweets.copy()\n",
    "B_tweets_del.remove_nodes_from(list(nx.isolates(B_tweets_del))) # delete the isolated nodes\n",
    "\n",
    "print('-------------')\n",
    "print(f'After deleting the isolated nodes, the network has {len(B_tweets_del.nodes)} nodes and {len(B_tweets_del.edges)} edges.')\n",
    "\n",
    "B_tweets_del_comp = [len(c) for c in sorted(nx.connected_components(B_tweets_del), key=len, reverse=True)]\n",
    "print(f'There are {len(B_tweets_del_comp)} connected components in the network and the largest one has {max(B_tweets_del_comp)} nodes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Density:\t\t\t 0.01052555168408827\n",
      "Network diameter:\t\t 25\n",
      "Average shortest path length:\t 10.110506194347657\n",
      "Average degree:\t\t\t 3.0208333333333335\n",
      "-------------\n",
      "Node with the highest degree centrality:\t\t 90723\n",
      "Node with the lowest degree centrality:\t\t\t 87556\n",
      "\n",
      "Node with the highest betweenese degree centrality:\t 90723\n",
      "Node with the lowest betweenese degree centrality:\t 87556\n",
      "\n",
      "Node with the highest closeness degree centrality:\t 97273\n",
      "Node with the lowest closeness degree centrality:\t 79917\n",
      "\n",
      "Node with the highest eigenvector degree centrality:\t 85563\n",
      "Node with the lowest eigenvector degree centrality:\t 105171\n",
      "\n",
      "Node with the highest load degree centrality:\t\t 90723\n",
      "Node with the lowest load degree centrality:\t\t 87556\n"
     ]
    }
   ],
   "source": [
    "# create a subgraph that is the largest connected component\n",
    "S_tweets_del = max(nx.connected_components(B_tweets_del), key=len)\n",
    "S_tweets_del = B_tweets_del.subgraph(S_tweets_del)\n",
    "print('-------------')\n",
    "print(f'Density:\\t\\t\\t {nx.density(S_tweets_del)}')\n",
    "print(f'Network diameter:\\t\\t {nx.diameter(S_tweets_del)}')\n",
    "print(f'Average shortest path length:\\t {nx.average_shortest_path_length(S_tweets_del)}')\n",
    "print(f'Average degree:\\t\\t\\t {sum([v for (u,v) in list(nx.degree(S_tweets_del))]) / len(S_tweets_del)}')\n",
    "print('-------------')\n",
    "degree_insect = dict(nx.degree_centrality(S_tweets_del))\n",
    "print(f'Node with the highest degree centrality:\\t\\t {max(degree_insect, key=degree_insect.get)}')\n",
    "print(f'Node with the lowest degree centrality:\\t\\t\\t {min(degree_insect, key=degree_insect.get)}')\n",
    "print('')\n",
    "betweenness = dict(nx.betweenness_centrality(S_tweets_del))\n",
    "print(f'Node with the highest betweenese degree centrality:\\t {max(betweenness, key=betweenness.get)}')\n",
    "print(f'Node with the lowest betweenese degree centrality:\\t {min(betweenness, key=betweenness.get)}')\n",
    "print('')\n",
    "closeness = dict(nx.closeness_centrality(S_tweets_del))\n",
    "print(f'Node with the highest closeness degree centrality:\\t {max(closeness, key=closeness.get)}')\n",
    "print(f'Node with the lowest closeness degree centrality:\\t {min(closeness, key=closeness.get)}')\n",
    "print('')\n",
    "eigenvector = dict(nx.eigenvector_centrality(S_tweets_del))\n",
    "print(f'Node with the highest eigenvector degree centrality:\\t {max(eigenvector, key=eigenvector.get)}')\n",
    "print(f'Node with the lowest eigenvector degree centrality:\\t {min(eigenvector, key=eigenvector.get)}')\n",
    "print('')\n",
    "load = dict(nx.load_centrality(S_tweets_del))\n",
    "print(f'Node with the highest load degree centrality:\\t\\t {max(load, key=load.get)}')\n",
    "print(f'Node with the lowest load degree centrality:\\t\\t {min(load, key=load.get)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7abe0519a6191451e7f8db70f9d941d7f04cf20d8ebf6fe38ded5796f8212f0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
