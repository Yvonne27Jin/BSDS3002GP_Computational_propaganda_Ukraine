{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Network analysis\n",
    "# Centralities\n",
    "# Clusters\n",
    "# Bot detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"preprocessed_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bot detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral        96528\n",
       "Unknown        37371\n",
       "pro_Ukraine    27098\n",
       "pro_Russian      559\n",
       "Both              72\n",
       "Name: NodeType, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"NodeType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_UkraineBefore = data[\"userid\"][(data[\"NodeType\"] == \"pro_Ukraine\") & (data[\"tweetcreatedts\"] <= \"2022-03-04 23:59:59+00:00\")].sample(10)\n",
    "pro_UkraineAfter = data[\"userid\"][(data[\"NodeType\"] == \"pro_Ukraine\") & (data[\"tweetcreatedts\"] > \"2022-03-04 23:59:59+00:00\")].sample(10)\n",
    "pro_RussianBefore = data[\"userid\"][(data[\"NodeType\"] == \"pro_Russian\") & (data[\"tweetcreatedts\"] <= \"2022-03-04 23:59:59+00:00\")].sample(10)\n",
    "pro_RussianAfter = data[\"userid\"][(data[\"NodeType\"] == \"pro_Russian\") & (data[\"tweetcreatedts\"] > \"2022-03-04 23:59:59+00:00\")].sample(10)\n",
    "\n",
    "groups = {\"pro_UkraineBefore\": pro_UkraineBefore, \"pro_UkraineAfter\": pro_UkraineAfter, \"pro_RussianBefore\":pro_RussianBefore, \"pro_RussianAfter\":pro_RussianAfter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get results from botometer\n",
    "# More info: https://github.com/IUNetSci/botometer-python\n",
    "\n",
    "# !pip3 install botometer\n",
    "# !pip3 install requests tweepy #dependencies for botometer\n",
    "import botometer, csv\n",
    "from config import *\n",
    "\n",
    "bom = botometer.Botometer(wait_on_ratelimit=True,\n",
    "                          rapidapi_key=rapidapi_key,\n",
    "                          **twitter_app_auth)\n",
    "\n",
    "with open('group_results.csv', 'a', encoding=\"utf-8\") as file:\n",
    "    w = csv.writer(file)\n",
    "\n",
    "    group_results = dict()\n",
    "    for group in groups.items():\n",
    "        accounts = group[1]\n",
    "        results = []     \n",
    "        for screen_name, result in bom.check_accounts_in(accounts):\n",
    "            w.writerow([group[0], screen_name, result])\n",
    "            results.append(result)\n",
    "        group_results[group[0]] = results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n",
      "pro_UkraineBefore    75\n",
      "pro_UkraineAfter     75\n",
      "pro_RussianBefore    75\n",
      "pro_RussianAfter     75\n",
      "Name: group, dtype: int64\n",
      "Group: pro_RussianAfter\n",
      "Number of bots: 9\n",
      "Mean score EN: 0.3645 Mean score UNIVERSAL: 0.3478\n",
      "Group: pro_RussianBefore\n",
      "Number of bots: 4\n",
      "Mean score EN: 0.4216 Mean score UNIVERSAL: 0.3706\n",
      "Group: pro_UkraineAfter\n",
      "Number of bots: 13\n",
      "Mean score EN: 0.4616 Mean score UNIVERSAL: 0.3769\n",
      "Group: pro_UkraineBefore\n",
      "Number of bots: 15\n",
      "Mean score EN: 0.5144 Mean score UNIVERSAL: 0.4297\n"
     ]
    }
   ],
   "source": [
    "# Check results. If bot: add results to the attributes\n",
    "import ast\n",
    "\n",
    "bot_data = pd.read_csv(\"group_results.csv\")\n",
    "print(bot_data.shape)\n",
    "print(bot_data[\"group\"].value_counts())\n",
    "bot_data = bot_data.groupby(by=\"group\")\n",
    "\n",
    "bot_scores = dict()\n",
    "bot_score_means = dict()\n",
    "\n",
    "for group, scores in bot_data:\n",
    "    non_existing = 0\n",
    "    sum_en = 0\n",
    "    sum_un = 0\n",
    "    nbots = 0\n",
    "    for result in scores[\"bot_scores\"]:\n",
    "        result = ast.literal_eval(result)\n",
    "        try:\n",
    "            english_benchmark = result[\"cap\"][\"english\"]\n",
    "            universal_benchmark = result[\"cap\"][\"universal\"]\n",
    "            english_score = result[\"raw_scores\"][\"english\"][\"overall\"]\n",
    "            universal_score = result[\"raw_scores\"][\"universal\"][\"overall\"]\n",
    "\n",
    "            bot_en = False\n",
    "            if english_score >= english_benchmark:\n",
    "                bot_en = True\n",
    "                \n",
    "            bot_uni = False\n",
    "            if universal_score >= universal_benchmark:\n",
    "                bot_uni = True\n",
    "                \n",
    "            if bot_en or bot_uni:\n",
    "                english_all_scores = result[\"raw_scores\"][\"english\"]\n",
    "                universal_all_scores = result[\"raw_scores\"][\"universal\"]\n",
    "                nbots += 1\n",
    "                # add bot scores attribute to the node\n",
    "                bot_scores[result[\"user\"][\"user_data\"][\"screen_name\"]] = {\"en\": english_all_scores, \"un\": universal_all_scores}\n",
    "            \n",
    "            sum_en += english_score\n",
    "            sum_un += universal_score\n",
    "        except:\n",
    "            non_existing +=1\n",
    "            continue\n",
    "    mean_en = sum_en/(len(scores)-non_existing)\n",
    "    mean_un = sum_un/(len(scores)-non_existing)\n",
    "\n",
    "    bot_score_means[group] = {\"en\": mean_en, \"un\": mean_un}\n",
    "\n",
    "    print(\"Group:\", group)\n",
    "    print(\"Number of bots:\",nbots)\n",
    "    print(\"Mean score EN:\",round(mean_en, 4),\"Mean score UNIVERSAL:\",round(mean_un, 4))\n",
    "\n",
    "# example result: {'cap':\n",
    "#   {'english': 0.8995513244218455, 'universal': 0.8733944954488508},\n",
    "#       'display_scores':\n",
    "#           {'english': {'astroturf': 0.8, 'fake_follower': 1.9, 'financial': 0.2, 'other': 4.7, 'overall': 4.7, 'self_declared': 4.6, 'spammer': 0.8},\n",
    "#           universal': {'astroturf': 0.8, 'fake_follower': 1.2, 'financial': 0.2, 'other': 4.4, 'overall': 4.6, 'self_declared': 4.6, 'spammer': 0.8}},\n",
    "#       'raw_scores':\n",
    "#           {'english': {'astroturf': 0.17, 'fake_follower': 0.38, 'financial': 0.03, 'other': 0.94, 'overall': 0.94, 'self_declared': 0.93, 'spammer': 0.16},\n",
    "#           'universal': {'astroturf': 0.15, 'fake_follower': 0.24, 'financial': 0.04, 'other': 0.87, 'overall': 0.91, 'self_declared': 0.91, 'spammer': 0.15}},\n",
    "#   'user': {'majority_lang': 'en', 'user_bot_data': {'id_str': '3380828067', 'screen_name': 'dsn_status'}}}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7abe0519a6191451e7f8db70f9d941d7f04cf20d8ebf6fe38ded5796f8212f0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
