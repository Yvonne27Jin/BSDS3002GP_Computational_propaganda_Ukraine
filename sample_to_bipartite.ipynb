{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all sampled tweets 163204\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# turn off scientific notation for large id numbers\n",
    "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
    "\n",
    "sampled = pd.read_csv(\"sampled_dataset_full_column.csv\", lineterminator='\\n')\n",
    "print(\"Number of all sampled tweets\", len(sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total retweets number 65575\n"
     ]
    }
   ],
   "source": [
    "# Get number of tweets with repeated text (retweets)\n",
    "retweets_all = sampled[\"text\"].duplicated()\n",
    "number_all = len(retweets_all[retweets_all == True])\n",
    "print(\"Total retweets number\",number_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53158, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter tweets by time period: all until March 13th\n",
    "time_filtered = sampled[(sampled['tweetcreatedts'] < '2022-03-13 24:59:59+00:00')]\n",
    "time_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total retweets number until March 13th: 17255\n"
     ]
    }
   ],
   "source": [
    "# Get number of tweets with repeated text (retweets) in filtered dataset\n",
    "retweets = time_filtered[\"text\"].duplicated()\n",
    "number = len(retweets[retweets == True])\n",
    "print(\"Total retweets number until March 13th:\", number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17255, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only duplicates (removing tweets without retweets for easier network analysis)\n",
    "duplicates = time_filtered.loc[retweets]\n",
    "duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for text id for easier work with nodes in network\n",
    "unique = duplicates[\"text\"].drop_duplicates(keep=\"first\")\n",
    "unique_hash = {text: i for i, text in unique.items()}\n",
    "unique_keys = unique_hash.keys() #texts\n",
    "unique_values = unique_hash.values() #indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert text id column to the dataset \n",
    "duplicates.insert(loc=2, column=\"textid\", value=[unique_hash[x] for x in duplicates[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_columns = [\"userid\",'username', 'location', 'tweetid','tweetcreatedts', 'retweetcount', 'hashtags', 'text', 'usercreatedts','following', 'followers', 'totaltweets']\n",
    "# columns = [\"userid\",'tweetid','tweetcreatedts', 'hashtags', 'text', 'usercreatedts','following', 'followers', 'totaltweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nodes for bipartite network\n",
    "users = duplicates[\"userid\"]\n",
    "tweets = duplicates[\"textid\"]\n",
    "\n",
    "# Create edge list for bipartite network\n",
    "column_e = [\"userid\", \"textid\"]\n",
    "edgelist = [(user, textid) for user, textid in duplicates[columns].values]\n",
    "\n",
    "edges = pd.DataFrame(edgelist,columns = column_e)\n",
    "\n",
    "edges.to_csv(\"edgelist_UtoT.csv\",sep = \",\", header = True, encoding = \"UTF-8\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "B = nx.Graph()\n",
    "B.add_nodes_from(users, bipartite=0)\n",
    "B.add_nodes_from(tweets, bipartite=1)\n",
    "B.add_edges_from(edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 16315 nodes and 256226 edges\n",
      "Graph with 5244 nodes and 1114 edges\n"
     ]
    }
   ],
   "source": [
    "from networkx.algorithms import bipartite\n",
    "\n",
    "users_nodes = {n for n, a in B.nodes(data=True) if a[\"bipartite\"] == 0}\n",
    "tweets_nodes = set(B) - users_nodes\n",
    "\n",
    "B_users = bipartite.projected_graph(B, users_nodes)\n",
    "B_tweets = bipartite.projected_graph(B, tweets_nodes)\n",
    "# 16315 256226\n",
    "#5244 1114\n",
    "\n",
    "B_users_w = bipartite.weighted_projected_graph(B, users_nodes)\n",
    "B_tweets_w = bipartite.weighted_projected_graph(B, tweets_nodes)\n",
    "\n",
    "print(nx.info(B_users_w))\n",
    "print(nx.info(B_tweets_w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undirected, unweighted\n",
    "nx.is_directed(B_users)\n",
    "nx.is_weighted(B_users_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write edgelist of projected network\n",
    "nx.write_weighted_edgelist(B_users, \"projected_w_user_edgelist.csv\", delimiter=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare two timeframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6505, 15)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter tweets by time period: before and after the tweeter ban \n",
    "time_before = duplicates[(duplicates['tweetcreatedts'] < '2022-03-04 24:59:59+00:00')]\n",
    "time_after = duplicates[(duplicates['tweetcreatedts'] > '2022-03-04 24:59:59+00:00')]\n",
    "time_before.shape #23156 tweets -> 6505 replicated retweets\n",
    "time_after.shape  #30002 tweets -> 10750 replicated retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) timeframe1: before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 6398 nodes and 68226 edges\n",
      "Graph with 2267 nodes and 107 edges\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for text id for easier work with nodes in network\n",
    "unique = time_before[\"text\"].drop_duplicates(keep=\"first\")\n",
    "unique_hash = {text: i for i, text in unique.items()}\n",
    "unique_keys = unique_hash.keys() #texts\n",
    "unique_values = unique_hash.values() #indexes\n",
    "\n",
    "# Get nodes for bipartite network\n",
    "users = time_before[\"userid\"]\n",
    "tweets = time_before[\"textid\"]\n",
    "\n",
    "# Create edge list for bipartite network\n",
    "column_e = [\"userid\", \"textid\"]\n",
    "edgelist = [(user, textid) for user, textid in time_before[columns].values]\n",
    "\n",
    "edges = pd.DataFrame(edgelist,columns = column_e)\n",
    "\n",
    "edges.to_csv(\"edgelist_UtoT_t1.csv\",sep = \",\", header = True, encoding = \"UTF-8\",index=False)\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "B1 = nx.Graph()\n",
    "B1.add_nodes_from(users, bipartite=0)\n",
    "B1.add_nodes_from(tweets, bipartite=1)\n",
    "B1.add_edges_from(edgelist)\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "users_nodes = {n for n, a in B1.nodes(data=True) if a[\"bipartite\"] == 0}\n",
    "tweets_nodes = set(B1) - users_nodes\n",
    "\n",
    "B1_users = bipartite.projected_graph(B1, users_nodes)\n",
    "B1_tweets = bipartite.projected_graph(B1, tweets_nodes)\n",
    "# 16315 256226\n",
    "#5244 1114\n",
    "\n",
    "B1_users_w = bipartite.weighted_projected_graph(B1, users_nodes)\n",
    "B1_tweets_w = bipartite.weighted_projected_graph(B1, tweets_nodes)\n",
    "\n",
    "print(nx.info(B1_users_w))\n",
    "print(nx.info(B1_tweets_w))\n",
    "\n",
    "# write edgelist of projected network\n",
    "nx.write_weighted_edgelist(B1_users, \"projected_w_user_edgelist_1.csv\", delimiter=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) timeframe2: after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 10164 nodes and 173330 edges\n",
      "Graph with 3190 nodes and 670 edges\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for text id for easier work with nodes in network\n",
    "unique = time_after[\"text\"].drop_duplicates(keep=\"first\")\n",
    "unique_hash = {text: i for i, text in unique.items()}\n",
    "unique_keys = unique_hash.keys() #texts\n",
    "unique_values = unique_hash.values() #indexes\n",
    "\n",
    "# Get nodes for bipartite network\n",
    "users = time_after[\"userid\"]\n",
    "tweets = time_after[\"textid\"]\n",
    "\n",
    "# Create edge list for bipartite network\n",
    "column_e = [\"userid\", \"textid\"]\n",
    "edgelist = [(user, textid) for user, textid in time_after[columns].values]\n",
    "\n",
    "edges = pd.DataFrame(edgelist,columns = column_e)\n",
    "\n",
    "edges.to_csv(\"edgelist_UtoT_t2.csv\",sep = \",\", header = True, encoding = \"UTF-8\",index=False)\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "B2 = nx.Graph()\n",
    "B2.add_nodes_from(users, bipartite=0)\n",
    "B2.add_nodes_from(tweets, bipartite=1)\n",
    "B2.add_edges_from(edgelist)\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "users_nodes = {n for n, a in B2.nodes(data=True) if a[\"bipartite\"] == 0}\n",
    "tweets_nodes = set(B2) - users_nodes\n",
    "\n",
    "B2_users = bipartite.projected_graph(B2, users_nodes)\n",
    "B2_tweets = bipartite.projected_graph(B2, tweets_nodes)\n",
    "# 16315 256226\n",
    "#5244 1114\n",
    "\n",
    "B2_users_w = bipartite.weighted_projected_graph(B2, users_nodes)\n",
    "B2_tweets_w = bipartite.weighted_projected_graph(B2, tweets_nodes)\n",
    "\n",
    "print(nx.info(B2_users_w))\n",
    "print(nx.info(B2_tweets_w))\n",
    "\n",
    "# write edgelist of projected network\n",
    "nx.write_weighted_edgelist(B2_users, \"projected_w_user_edgelist_2.csv\", delimiter=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchial clustering \n",
    "\n",
    "# from collections import defaultdict\n",
    "# import numpy as np\n",
    "# from scipy.cluster import hierarchy\n",
    "# from scipy.spatial import distance\n",
    "# from builtins import next\n",
    "\n",
    "# def create_hc(G, t):\n",
    "#     \"\"\"Creates hierarchical cluster of graph G from distance matrix\"\"\"\n",
    "#     path_length = nx.all_pairs_shortest_path_length(G)\n",
    "#     distances = np.zeros((len(G), len(G)))\n",
    "#     for u, p in path_length:\n",
    "#         for v, d in p.items():\n",
    "#             distances[u][v] = d\n",
    "#     # Create hierarchical cluster\n",
    "#     Y = distance.squareform(distances)\n",
    "#     Z = hierarchy.complete(Y)  # Creates HC using farthest point linkage\n",
    "    \n",
    "#     membership = list(hierarchy.fcluster(Z, t = t))\n",
    "    \n",
    "#     # Create collection of lists for blockmodel\n",
    "#     partition = defaultdict(list)\n",
    "#     for n, p in zip(list(range(len(G))), membership):\n",
    "#         partition[p].append(n)\n",
    "#     return list(partition.values())\n",
    "\n",
    "# # Users network\n",
    "# G = B_users.copy()\n",
    "\n",
    "# x = nx.connected_components(G)\n",
    "# sub = next(x)\n",
    "\n",
    "# # Extract largest connected component into graph H\n",
    "# H = G.subgraph(sub)\n",
    "# # Makes life easier to have consecutively labeled integer nodes\n",
    "# H = nx.convert_node_labels_to_integers(H)\n",
    "# # Create parititions with hierarchical clustering\n",
    "# partitions = create_hc(H, 0.5)\n",
    "# # Build blockmodel graph\n",
    "# BM = nx.quotient_graph(H, partitions, relabel=True)\n",
    "\n",
    "# # Draw block model with nodes sized by number of internal nodes\n",
    "# # node_size = [H.nodes[x][\"nnodes\"] * 100 for x in H.nodes()]\n",
    "# nx.draw(B_users, width=0.2, with_labels=False)\n",
    "# # node_size = [BM.nodes[x][\"nnodes\"] * 100 for x in BM.nodes()]\n",
    "# # nx.draw(BM, node_size=node_size, width=0.2, with_labels=False)\n",
    "# plt.title(\"One-mode network of users\")\n",
    "# plt.savefig(\"users_net.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users network\n",
    "fig,ax = plt.subplots(1,1,figsize=(20,15))\n",
    "node_size = [x for x in nx.degree_centrality(B_users)]\n",
    "pos = nx.spring_layout(B_users, k=0.3)\n",
    "nx.draw_networkx(B_users, pos, node_size=node_size, width=0.1, with_labels = False,alpha=0.7,edgecolors='w', edge_color='#999990')\n",
    "ax.set_title('One-mode users network', fontsize=16)\n",
    "ax.set_axis_off()\n",
    "plt.savefig(\"users_net.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7abe0519a6191451e7f8db70f9d941d7f04cf20d8ebf6fe38ded5796f8212f0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
